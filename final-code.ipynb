{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 13885877,
     "sourceType": "datasetVersion",
     "datasetId": 8846952
    },
    {
     "sourceId": 14053250,
     "sourceType": "datasetVersion",
     "datasetId": 8945448
    },
    {
     "sourceId": 14071327,
     "sourceType": "datasetVersion",
     "datasetId": 8903667
    },
    {
     "sourceId": 14072039,
     "sourceType": "datasetVersion",
     "datasetId": 8957446
    },
    {
     "sourceId": 677572,
     "sourceType": "modelInstanceVersion",
     "isSourceIdPinned": true,
     "modelInstanceId": 513809,
     "modelId": 528448
    }
   ],
   "dockerImageVersionId": 31193,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "\n",
    "class TextCleaner:\n",
    "    @staticmethod\n",
    "    def replace_regex(text, pattern, replacement=''):\n",
    "        return pattern.sub(replacement, text)\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_lines(lines):\n",
    "        for i in range(len(lines)):\n",
    "            # remove any brackets that have only numbers inside and remove all numbers\n",
    "            reg = r'\\(\\s*(\\d+)\\s*\\)|\\(\\s*(\\d+)\\s*\\/\\s*(\\d+)\\s*\\)|\\d+'\n",
    "            lines[i] = TextCleaner.replace_regex(lines[i], re.compile(reg))\n",
    "            # replace all different types of brackets with a single type\n",
    "            reg_brackets = r'[\\[\\{\\(\\]\\}\\)]'\n",
    "            lines[i] = re.compile(reg_brackets).sub('', lines[i])\n",
    "            # remove some unwanted characters\n",
    "            reg = r'[/\\/\\\\\\-]'\n",
    "            lines[i] = TextCleaner.replace_regex(lines[i], re.compile(reg))\n",
    "            # remove unwanted characters\n",
    "            reg = r'[,»–\\';«*\\u200f\\u200d\\u200b\\u200c\\u200e\"\\\\~`%…_]'\n",
    "            lines[i] = TextCleaner.replace_regex(lines[i], re.compile(reg))\n",
    "            # remove English characters (a-z, A-Z)\n",
    "            reg = r'[a-zA-Z]'\n",
    "            lines[i] = TextCleaner.replace_regex(lines[i], re.compile(reg))\n",
    "            # remove fractions and superscripts/subscripts\n",
    "            reg = r'[\\u00BC-\\u00BE\\u2150-\\u215E]'\n",
    "            lines[i] = TextCleaner.replace_regex(lines[i], re.compile(reg))\n",
    "            # remove emojis and other symbols\n",
    "            reg = r'[\\U0001F000-\\U0001FFFF]'\n",
    "            lines[i] = TextCleaner.replace_regex(lines[i], re.compile(reg))\n",
    "            # remove gender symbols and similar miscellaneous symbols\n",
    "            reg = r'[\\u2600-\\u26FF\\u2700-\\u27BF]'\n",
    "            lines[i] = TextCleaner.replace_regex(lines[i], re.compile(reg))\n",
    "            # remove extra spaces\n",
    "            reg = r'\\s+'\n",
    "            lines[i] = TextCleaner.replace_regex(lines[i], re.compile(reg), ' ')\n",
    "        return lines\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_diacritics(lines):\n",
    "        diacritics_pattern = r'[\\u064B-\\u065F\\u0670\\uFE70-\\uFE7F]'\n",
    "        for i in range(len(lines)):\n",
    "            lines[i] = TextCleaner.replace_regex(lines[i], re.compile(diacritics_pattern))\n",
    "        return lines\n",
    "\n",
    "    @staticmethod\n",
    "    def count_spaces(text):\n",
    "        return len(re.findall(r'\\s', text))"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T23:19:36.714674Z",
     "iopub.execute_input": "2025-12-09T23:19:36.714948Z",
     "iopub.status.idle": "2025-12-09T23:19:36.737854Z",
     "shell.execute_reply.started": "2025-12-09T23:19:36.714932Z",
     "shell.execute_reply": "2025-12-09T23:19:36.737272Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": "import re\nimport textwrap\n\n\nclass TextPreprocessor:\n    def __init__(self, cleaner, input_path='.', output_path='.', max_length=600, with_labels=True):\n        self.cleaner = cleaner\n        self.input_path = input_path\n        self.output_path = output_path\n        self.max_length = max_length\n        self.with_labels = with_labels\n\n    def clean_lines(self, lines, data_type):\n        lines = self.cleaner.clean_lines(lines)\n\n        if not lines:\n            return lines\n\n        # Save lines with diacritics\n        if self.with_labels:\n            with open(f'{self.output_path}cleaned_{data_type}_with_diacritics.txt', 'a+', encoding='utf-8') as f:\n                f.write('\\n'.join(lines) + '\\n')\n\n        # Remove diacritics\n        lines_no_diacritics = self.cleaner.remove_diacritics(lines)\n\n        # Save lines without diacritics\n        with open(f'{self.output_path}cleaned_{data_type}_without_diacritics.txt', 'a+', encoding='utf-8') as f:\n            f.write('\\n'.join(lines_no_diacritics) + '\\n')\n\n        return lines_no_diacritics\n\n    def preprocess_file(self, data_type, limit=None):\n        # Clear previous output\n        open(f'{self.output_path}cleaned_{data_type}_with_diacritics.txt', 'w', encoding='utf-8').close()\n        open(f'{self.output_path}cleaned_{data_type}_without_diacritics.txt', 'w', encoding='utf-8').close()\n\n        # Read raw file\n        with open(f'{self.input_path}{data_type}.txt', 'r', encoding='utf-8') as f:\n            lines = [line.strip() for line in f.readlines()]\n\n        if limit is not None:\n            lines = lines[:limit]\n\n        return self.clean_lines(lines, data_type)\n\n    def tokenize_file(self, data_type):\n        tokenized_no_diacritics = []\n        space_counts = []\n\n        # Tokenize file without diacritics\n        with open(f'{self.output_path}cleaned_{data_type}_without_diacritics.txt', 'r', encoding='utf-8') as f:\n            for line in f:\n                line = re.sub(r'[\\n\\r\\t]', '', line)\n                line = re.sub(r'\\s+', ' ', line).strip()\n                sentences = textwrap.wrap(line, self.max_length)\n                for sentence in sentences:\n                    tokenized_no_diacritics.append(sentence)\n                    space_counts.append(self.cleaner.count_spaces(sentence))\n\n        tokenized_with_diacritics = []\n\n        if self.with_labels:\n            space_index = 0\n            with open(f'{self.output_path}cleaned_{data_type}_with_diacritics.txt', 'r', encoding='utf-8') as f:\n                for line in f:\n                    line = re.sub(r'[\\n\\r\\t]', '', line)\n                    line = re.sub(r'\\s+', ' ', line).strip()\n                    remaining_text = line\n                    while remaining_text:\n                        spaces_to_include = space_counts[space_index]\n                        space_index += 1\n                        words = remaining_text.split()\n                        if len(words) <= spaces_to_include + 1:\n                            tokenized_with_diacritics.append(remaining_text.strip())\n                            break\n                        sentence = ' '.join(words[:spaces_to_include + 1])\n                        tokenized_with_diacritics.append(sentence.strip())\n                        remaining_text = ' '.join(words[spaces_to_include + 1:]).strip()\n\n        return tokenized_no_diacritics, tokenized_with_diacritics\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T23:19:36.794164Z",
     "iopub.execute_input": "2025-12-09T23:19:36.794386Z",
     "iopub.status.idle": "2025-12-09T23:19:36.806627Z",
     "shell.execute_reply.started": "2025-12-09T23:19:36.794369Z",
     "shell.execute_reply": "2025-12-09T23:19:36.805833Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "class DatasetBuilder:\n",
    "    def __init__(self, preprocessor, char_to_index, label_map, max_length=600, device='cpu'):\n",
    "        self.preprocessor = preprocessor\n",
    "        self.char_to_index = char_to_index\n",
    "        self.label_map = label_map\n",
    "        self.max_length = max_length\n",
    "        self.device = device\n",
    "\n",
    "    def encode_chars(self, sequences):\n",
    "        indexed = [[self.char_to_index[char] for char in seq] for seq in sequences]\n",
    "        padded = [seq + [0] * (self.max_length - len(seq)) for seq in indexed]\n",
    "        return torch.tensor(padded).to(self.device)\n",
    "\n",
    "    def encode_labels(self, sequences_with_diacritics):\n",
    "        all_labels = []\n",
    "\n",
    "        for sentence in sequences_with_diacritics:\n",
    "            labels = []\n",
    "            i = 0\n",
    "            length = len(sentence)\n",
    "\n",
    "            while i < length:\n",
    "                ch = ord(sentence[i])\n",
    "\n",
    "                # letter\n",
    "                if ch not in self.label_map:\n",
    "\n",
    "                    # Check next character\n",
    "                    if i + 1 < length:\n",
    "                        d1 = ord(sentence[i + 1])\n",
    "\n",
    "                        # shadda + another diacritic\n",
    "                        if d1 == 1617 and i + 2 < length:\n",
    "                            d2 = ord(sentence[i + 2])\n",
    "                            if d2 in self.label_map:\n",
    "                                labels.append(self.label_map[(1617, d2)])\n",
    "                                i += 3\n",
    "                                continue\n",
    "\n",
    "                        # only shadda\n",
    "                        if d1 == 1617:\n",
    "                            labels.append(self.label_map[1617])\n",
    "                            i += 2\n",
    "                            continue\n",
    "\n",
    "                        # one diacritic\n",
    "                        if d1 in self.label_map:\n",
    "                            labels.append(self.label_map[d1])\n",
    "                            i += 2\n",
    "                            continue\n",
    "\n",
    "                    # no diacritic\n",
    "                    labels.append(14)\n",
    "\n",
    "                i += 1\n",
    "\n",
    "            # pad\n",
    "            if len(labels) < self.max_length:\n",
    "                labels.extend([15] * (self.max_length - len(labels)))\n",
    "\n",
    "            all_labels.append(labels)\n",
    "\n",
    "        return torch.tensor(all_labels, device=self.device)\n",
    "\n",
    "    def create_dataloader(self, data_type, batch_size=256, with_labels=True):\n",
    "        self.preprocessor.preprocess_file(data_type)\n",
    "        sequences, sequences_with_diacritics = self.preprocessor.tokenize_file(data_type)\n",
    "\n",
    "        data_tensor = self.encode_chars(sequences)\n",
    "\n",
    "        if with_labels:\n",
    "            labels_tensor = self.encode_labels(sequences_with_diacritics)\n",
    "            dataset = TensorDataset(data_tensor, labels_tensor)\n",
    "        else:\n",
    "            dataset = TensorDataset(data_tensor)\n",
    "\n",
    "        return DataLoader(dataset, batch_size=batch_size)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T23:19:36.807986Z",
     "iopub.execute_input": "2025-12-09T23:19:36.808323Z",
     "iopub.status.idle": "2025-12-09T23:19:36.836132Z",
     "shell.execute_reply.started": "2025-12-09T23:19:36.808297Z",
     "shell.execute_reply": "2025-12-09T23:19:36.835396Z"
    }
   },
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import BatchNorm1d\n",
    "import pickle\n",
    "import json\n",
    "\n",
    "\n",
    "class CharBiLSTM(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocab_size=44,\n",
    "        embedding_dim=300,\n",
    "        hidden_dim=256,\n",
    "        output_dim=16,\n",
    "        dropout_rate=0.2,\n",
    "        num_layers=1,\n",
    "        max_length=600,\n",
    "    ):\n",
    "        super(CharBiLSTM, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "            dropout=dropout_rate,\n",
    "        )\n",
    "        self.batchnorm = nn.BatchNorm1d(max_length)\n",
    "        self.output = nn.Linear(hidden_dim * 2, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_embed = self.embedding(x)\n",
    "        lstm_out, _ = self.lstm(x_embed)\n",
    "        lstm_out = self.batchnorm(lstm_out)\n",
    "        out = self.output(lstm_out)\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model_pkl(\n",
    "        model_file=\"best_model.pkl\", meta_file=\"best_model_meta.json\", device=None\n",
    "    ):\n",
    "        if device is None:\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        base_path = \"/kaggle/working/\"\n",
    "\n",
    "        with open(base_path + meta_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            metadata = json.load(f)\n",
    "\n",
    "        model = CharBiLSTM(\n",
    "            vocab_size=metadata[\"vocab_size\"],\n",
    "            embedding_dim=metadata[\"embedding_size\"],\n",
    "            hidden_dim=metadata[\"hidden_size\"],\n",
    "            output_dim=metadata[\"output_classes\"],\n",
    "            dropout_rate=metadata[\"dropout_rate\"],\n",
    "            num_layers=metadata[\"num_layers\"],\n",
    "            max_length=metadata[\"max_sequence_length\"],\n",
    "        ).to(device)\n",
    "\n",
    "        # state_dict = torch.load(base_path + model_file, map_location=device)\n",
    "        # model.load_state_dict(state_dict)\n",
    "        with open(base_path + model_file, \"rb\") as f:\n",
    "            state_dict = pickle.load(f)\n",
    "\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.to(device)\n",
    "\n",
    "        model.eval()\n",
    "        return model, metadata\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model_pth(\n",
    "        model_file=\"best_model.pth\", meta_file=\"best_model_meta.json\", device=None\n",
    "    ):\n",
    "        if device is None:\n",
    "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        base_path = \"./\"\n",
    "\n",
    "        with open(base_path + meta_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            metadata = json.load(f)\n",
    "\n",
    "        model = CharBiLSTM(\n",
    "            vocab_size=metadata[\"vocab_size\"],\n",
    "            embedding_dim=metadata[\"embedding_size\"],\n",
    "            hidden_dim=metadata[\"hidden_size\"],\n",
    "            output_dim=metadata[\"output_classes\"],\n",
    "            dropout_rate=metadata[\"dropout_rate\"],\n",
    "            num_layers=metadata[\"num_layers\"],\n",
    "            max_length=metadata[\"max_sequence_length\"],\n",
    "        ).to(device)\n",
    "\n",
    "        model.load_state_dict(torch.load(\"model_weights.pth\"))\n",
    "        model.to(device)\n",
    "\n",
    "        model.eval()\n",
    "        return model, metadata"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T23:21:25.613663Z",
     "iopub.execute_input": "2025-12-09T23:21:25.614252Z",
     "iopub.status.idle": "2025-12-09T23:21:25.622146Z",
     "shell.execute_reply.started": "2025-12-09T23:21:25.614233Z",
     "shell.execute_reply": "2025-12-09T23:21:25.621541Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from sklearn.metrics import f1_score\n",
    "from models import CharBiLSTM\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(\n",
    "        self, model, optimizer=None, scheduler=None, criterion=None,\n",
    "        train_loader=None, val_loader=None,\n",
    "        pad_idx=15, max_length=600, device=None,\n",
    "        checkpoint_file=\"checkpoint.pth\", best_model_file=\"best_model.pth\",\n",
    "        meta_file=\"best_model_meta.json\"\n",
    "    ):\n",
    "        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = model.to(self.device)\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "        self.scheduler = scheduler\n",
    "        self.criterion = criterion\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "\n",
    "        self.pad_idx = pad_idx\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.checkpoint_file = checkpoint_file\n",
    "        self.best_model_file = best_model_file\n",
    "        self.meta_file = meta_file\n",
    "\n",
    "        self.best_val_acc = -1\n",
    "\n",
    "        # Save metadata once\n",
    "        self._save_metadata()\n",
    "\n",
    "    def _save_metadata(self):\n",
    "        meta = {\n",
    "            \"vocab_size\": self.model.vocab_size,\n",
    "            \"embedding_size\": self.model.embedding.embedding_dim,\n",
    "            \"hidden_size\": self.model.hidden_size,\n",
    "            \"output_classes\": self.model.output_size,\n",
    "            \"dropout_rate\": self.model.dropout_rate,\n",
    "            \"num_layers\": self.model.num_layers,\n",
    "            \"max_sequence_length\": self.max_length,\n",
    "            \"learning_rate\": self.optimizer.param_groups[0][\"lr\"],\n",
    "            \"pad_idx\": self.pad_idx,\n",
    "        }\n",
    "\n",
    "        with open(self.meta_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(meta, f, indent=4)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_checkpoint(\n",
    "        checkpoint_file=\"checkpoint.pth\",\n",
    "        meta_file=\"best_model_meta.json\",\n",
    "        model=None,\n",
    "        device=None,\n",
    "    ):\n",
    "        device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        checkpoint = torch.load(checkpoint_file, map_location=device)\n",
    "\n",
    "        with open(meta_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            meta = json.load(f)\n",
    "\n",
    "        if model is None:\n",
    "            model = CharBiLSTM(\n",
    "                vocab_size=meta[\"vocab_size\"],\n",
    "                embedding_dim=meta[\"embedding_size\"],\n",
    "                hidden_dim=meta[\"hidden_size\"],\n",
    "                output_dim=meta[\"output_classes\"],\n",
    "                dropout_rate=meta[\"dropout_rate\"],\n",
    "                num_layers=meta[\"num_layers\"],\n",
    "                max_length=meta[\"max_sequence_length\"]\n",
    "            ).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=meta[\"learning_rate\"])\n",
    "        scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "        model.load_state_dict(checkpoint[\"model_state\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n",
    "\n",
    "        if checkpoint.get(\"scheduler_state\") is not None:\n",
    "            scheduler.load_state_dict(checkpoint[\"scheduler_state\"])\n",
    "\n",
    "        start_epoch = checkpoint[\"epoch\"] + 1\n",
    "        best_val_acc = checkpoint[\"best_val_acc\"]\n",
    "\n",
    "        return model, optimizer, scheduler, start_epoch, best_val_acc\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        correct, total = 0, 0\n",
    "        preds, trues = [], []\n",
    "\n",
    "        for batch_seq, batch_labels in self.train_loader:\n",
    "            batch_seq, batch_labels = batch_seq.to(self.device), batch_labels.to(self.device)\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            outputs = self.model(batch_seq)\n",
    "\n",
    "            flat_outputs = outputs.view(-1, outputs.shape[-1])\n",
    "            flat_labels = batch_labels.view(-1)\n",
    "            mask = (flat_labels != self.pad_idx)\n",
    "\n",
    "            loss = self.criterion(flat_outputs[mask], flat_labels[mask])\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            pred = flat_outputs.argmax(dim=1)\n",
    "            correct += (pred[mask] == flat_labels[mask]).sum().item()\n",
    "            total += mask.sum().item()\n",
    "\n",
    "            preds.extend(pred[mask].cpu().tolist())\n",
    "            trues.extend(flat_labels[mask].cpu().tolist())\n",
    "\n",
    "        acc = correct / total\n",
    "        f1 = f1_score(trues, preds, average='macro')\n",
    "        return acc, f1, loss.item()\n",
    "\n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        correct, total = 0, 0\n",
    "        preds, trues = [], []\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            for batch_seq, batch_labels in self.val_loader:\n",
    "                batch_seq, batch_labels = batch_seq.to(self.device), batch_labels.to(self.device)\n",
    "                outputs = self.model(batch_seq)\n",
    "\n",
    "                pred = outputs.argmax(dim=2)\n",
    "                flat_pred = pred.view(-1)\n",
    "                flat_labels = batch_labels.view(-1)\n",
    "                mask = (flat_labels != self.pad_idx)\n",
    "\n",
    "                correct += (flat_pred[mask] == flat_labels[mask]).sum().item()\n",
    "                total += mask.sum().item()\n",
    "\n",
    "                preds.extend(flat_pred[mask].cpu().tolist())\n",
    "                trues.extend(flat_labels[mask].cpu().tolist())\n",
    "\n",
    "        acc = correct / total\n",
    "        f1 = f1_score(trues, preds, average='macro')\n",
    "        return acc, f1\n",
    "\n",
    "    def train(self, num_epochs=20):\n",
    "        print(\"Training starts\")\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            train_acc, train_f1, loss_val = self.train_epoch()\n",
    "            val_acc, val_f1 = self.validate()\n",
    "\n",
    "            if self.scheduler:\n",
    "                self.scheduler.step()\n",
    "\n",
    "            print(\n",
    "                f\"Epoch {epoch+1}/{num_epochs} | Loss: {loss_val:.5f} | \"\n",
    "                f\"Train Acc: {train_acc*100:.2f}% | Train F1: {train_f1:.3f} | \"\n",
    "                f\"Val Acc: {val_acc*100:.2f}% | Val F1: {val_f1:.3f}\"\n",
    "            )\n",
    "\n",
    "            # SAVE BEST MODEL (based on val_acc)\n",
    "            if val_acc > self.best_val_acc:\n",
    "                self.best_val_acc = val_acc\n",
    "                torch.save(self.model.state_dict(), self.best_model_file)\n",
    "                print(f\"New best model saved! (Val Acc = {val_acc*100:.2f}%)\")\n",
    "\n",
    "            # SAVE LAST CHECKPOINT\n",
    "            torch.save({\n",
    "                \"model_state\": self.model.state_dict(),\n",
    "                \"optimizer_state\": self.optimizer.state_dict(),\n",
    "                \"scheduler_state\": self.scheduler.state_dict() if self.scheduler else None,\n",
    "                \"best_val_acc\": self.best_val_acc,\n",
    "                \"epoch\": epoch\n",
    "            }, self.checkpoint_file)\n",
    "\n",
    "        return self.best_val_acc\n",
    "\n",
    "    def test(self, test_loader):\n",
    "        self.model.eval()\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            for batch_seq, batch_labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "                batch_seq, batch_labels = batch_seq.to(self.device), batch_labels.to(self.device)\n",
    "                outputs = self.model(batch_seq)\n",
    "\n",
    "                pred_labels = outputs.argmax(dim=2)\n",
    "                mask = (batch_labels != self.pad_idx)\n",
    "\n",
    "                correct += ((pred_labels == batch_labels) & mask).sum().item()\n",
    "                total += mask.sum().item()\n",
    "\n",
    "        acc = correct / total if total > 0 else 0\n",
    "        print(f\"Test Accuracy: {acc*100:.3f}%\")\n",
    "        return acc"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T23:19:36.862255Z",
     "iopub.execute_input": "2025-12-09T23:19:36.862466Z",
     "iopub.status.idle": "2025-12-09T23:19:36.889833Z",
     "shell.execute_reply.started": "2025-12-09T23:19:36.862444Z",
     "shell.execute_reply": "2025-12-09T23:19:36.888999Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import re\n",
    "import textwrap\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "from cleaner import TextCleaner\n",
    "\n",
    "\n",
    "def convert2idx(data, char_to_index, max_len=200, device='cpu'):\n",
    "    sequences = [[char_to_index[ch] for ch in seq] for seq in data]\n",
    "    sequences = [seq + [0] * (max_len - len(seq)) for seq in sequences]\n",
    "    return torch.tensor(sequences, device=device)\n",
    "\n",
    "\n",
    "class Predictor:\n",
    "    def __init__(self, model, char_to_index, index_to_label, device=None):\n",
    "        self.model = model\n",
    "        self.char_to_index = char_to_index\n",
    "        self.index_to_label = index_to_label\n",
    "        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model.to(self.device)\n",
    "        self.IGNORE_IDX = {0, 2, 8, 15, 16, 26, 40, 43}\n",
    "    def predict_sentence(self, original_sentence, max_length=200, batch_size=256):\n",
    "        # Clean & normalize\n",
    "        clean = TextCleaner.clean_lines([original_sentence.strip()])[0]\n",
    "        clean = re.sub(r'[\\n\\r\\t]', '', clean)\n",
    "        clean = re.sub(r'\\s+', ' ', clean).strip()\n",
    "        cleaned_sentences = TextCleaner.remove_diacritics([clean])[0]\n",
    "        tokenized_sentences = []\n",
    "\n",
    "        # Split by dot\n",
    "        parts = [p.strip() for p in cleaned_sentences.split('.') if p.strip()]\n",
    "\n",
    "        # Wrap long strings without cutting words\n",
    "        for part in parts:\n",
    "            tokenized_sentences.extend(textwrap.wrap(part, max_length))\n",
    "\n",
    "        seq_tensor = convert2idx(tokenized_sentences, self.char_to_index, max_length, self.device)\n",
    "        loader = DataLoader(TensorDataset(seq_tensor, seq_tensor), batch_size=batch_size)\n",
    "\n",
    "        predicted_labels = []\n",
    "\n",
    "        # Run model\n",
    "        self.model.eval()\n",
    "        for batch_seq, batch_lbl in loader:\n",
    "            outputs = self.model(batch_seq)\n",
    "            batch_pred = outputs.argmax(dim=2)\n",
    "\n",
    "            # Mask ignored chars\n",
    "            mask = ~torch.isin(batch_seq, torch.tensor(list(self.IGNORE_IDX), device=self.device))\n",
    "            predicted_labels.extend(batch_pred[mask].tolist())\n",
    "\n",
    "        predicted_sentence = \"\"\n",
    "\n",
    "        idx = 0\n",
    "\n",
    "        for ch in cleaned_sentences:\n",
    "            predicted_sentence += ch\n",
    "\n",
    "            if ch not in self.char_to_index:\n",
    "                continue\n",
    "\n",
    "            code = self.char_to_index[ch]\n",
    "            if code in self.IGNORE_IDX:\n",
    "                continue\n",
    "\n",
    "            pred_class = self.index_to_label[predicted_labels[idx]]\n",
    "\n",
    "            if pred_class == 0:\n",
    "                idx += 1\n",
    "                continue\n",
    "\n",
    "            if isinstance(pred_class, tuple):\n",
    "                predicted_sentence += chr(pred_class[0]) + chr(pred_class[1])\n",
    "            else:\n",
    "                predicted_sentence += chr(pred_class)\n",
    "\n",
    "            idx += 1\n",
    "\n",
    "        return predicted_sentence\n",
    "\n",
    "    def predict_dataset(self, dataloader):\n",
    "        predicted_labels = []\n",
    "        ignore_indices = {0, 2, 8, 15, 16, 26, 40, 43}\n",
    "\n",
    "        self.model.eval()\n",
    "        with torch.inference_mode():\n",
    "            for batch_seq, _ in dataloader:\n",
    "                batch_seq = batch_seq.to(self.device)\n",
    "                outputs = self.model(batch_seq)\n",
    "                batch_pred = outputs.argmax(dim=2)\n",
    "\n",
    "                mask = ~torch.isin(batch_seq, torch.tensor(list(ignore_indices), device=self.device))\n",
    "\n",
    "                predicted_labels.extend(batch_pred[mask].tolist())\n",
    "\n",
    "        with open('submission.csv', 'w', encoding='utf-8') as f:\n",
    "            f.write('ID,label\\n')\n",
    "            for i, label in enumerate(predicted_labels):\n",
    "                f.write(f\"{i},{label}\\n\")\n",
    "\n",
    "        return predicted_labels\n",
    "\n",
    "    def evaluate(self, test_loader):\n",
    "        self.model.eval()\n",
    "        correct, total = 0, 0\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            for seq, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "                seq = seq.to(self.device)\n",
    "                labels = labels.to(self.device)\n",
    "\n",
    "                outputs = self.model(seq)\n",
    "                pred = outputs.argmax(dim=2)\n",
    "\n",
    "                flat_pred = pred.view(-1)\n",
    "                flat_labels = labels.view(-1)\n",
    "\n",
    "                # mask out PAD = 15\n",
    "                mask = (flat_labels != 15)\n",
    "\n",
    "                correct += (flat_pred[mask] == flat_labels[mask]).sum().item()\n",
    "                total += mask.sum().item()\n",
    "\n",
    "        return correct / total if total > 0 else 0\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T23:19:36.891510Z",
     "iopub.execute_input": "2025-12-09T23:19:36.891842Z",
     "iopub.status.idle": "2025-12-09T23:19:36.921206Z",
     "shell.execute_reply.started": "2025-12-09T23:19:36.891824Z",
     "shell.execute_reply": "2025-12-09T23:19:36.920495Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from cleaner import TextCleaner\n",
    "from preprocessor import TextPreprocessor\n",
    "from dataset_builder import DatasetBuilder\n",
    "from models import CharBiLSTM\n",
    "from trainer import Trainer\n",
    "from predictor import Predictor\n",
    "from tqdm import tqdm\n",
    "import gradio as gr\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "CHAR_TO_INDEX = {\n",
    "    \"د\": 1,\n",
    "    \"؟\": 2,\n",
    "    \"آ\": 3,\n",
    "    \"إ\": 4,\n",
    "    \"ؤ\": 5,\n",
    "    \"ط\": 6,\n",
    "    \"م\": 7,\n",
    "    \"،\": 8,\n",
    "    \"ة\": 9,\n",
    "    \"ت\": 10,\n",
    "    \"ر\": 11,\n",
    "    \"ئ\": 12,\n",
    "    \"ا\": 13,\n",
    "    \"ض\": 14,\n",
    "    \"!\": 15,\n",
    "    \" \": 16,\n",
    "    \"ك\": 17,\n",
    "    \"غ\": 18,\n",
    "    \"س\": 19,\n",
    "    \"ص\": 20,\n",
    "    \"أ\": 21,\n",
    "    \"ل\": 22,\n",
    "    \"ف\": 23,\n",
    "    \"ظ\": 24,\n",
    "    \"ج\": 25,\n",
    "    \"؛\": 26,\n",
    "    \"ن\": 27,\n",
    "    \"ع\": 28,\n",
    "    \"ب\": 29,\n",
    "    \"ث\": 30,\n",
    "    \"ه\": 31,\n",
    "    \"خ\": 32,\n",
    "    \"ى\": 33,\n",
    "    \"ء\": 34,\n",
    "    \"ز\": 35,\n",
    "    \"ق\": 36,\n",
    "    \"ي\": 37,\n",
    "    \"ش\": 38,\n",
    "    \"ح\": 39,\n",
    "    \":\": 40,\n",
    "    \"ذ\": 41,\n",
    "    \"و\": 42,\n",
    "    \".\": 43,\n",
    "}\n",
    "INDEX_TO_CHAR = {v: k for k, v in CHAR_TO_INDEX.items()}\n",
    "\n",
    "LABELS = {\n",
    "    1614: 0,\n",
    "    1611: 1,\n",
    "    1615: 2,\n",
    "    1612: 3,\n",
    "    1616: 4,\n",
    "    1613: 5,\n",
    "    1618: 6,\n",
    "    1617: 7,\n",
    "    (1617, 1614): 8,\n",
    "    (1617, 1611): 9,\n",
    "    (1617, 1615): 10,\n",
    "    (1617, 1612): 11,\n",
    "    (1617, 1616): 12,\n",
    "    (1617, 1613): 13,\n",
    "    0: 14,\n",
    "    15: 15,\n",
    "}\n",
    "INDEX_TO_LABEL = {v: k for k, v in LABELS.items()}\n",
    "\n",
    "MAX_LENGTH = 600\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VAL_BATCH_SIZE = 256\n",
    "READ_PATH = \"data/\"\n",
    "WRITE_PATH = \"cleaned_outputs/\"\n",
    "\n",
    "\n",
    "def test_last_char_text(\n",
    "    model,\n",
    "    data_loader,\n",
    "    max_len=600,\n",
    "    batch_size=256,\n",
    "    char_to_index=CHAR_TO_INDEX,\n",
    "    index_to_label=INDEX_TO_LABEL,\n",
    "    labels=LABELS,\n",
    "    index_to_char=INDEX_TO_CHAR,\n",
    "):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_last_char = 0\n",
    "    correct_last_char = 0\n",
    "    words_text = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch_sequences, batch_labels in tqdm(data_loader, desc=\"Last Char Test\"):\n",
    "            outputs = model(batch_sequences)  # batch_size * seq_length * output_size\n",
    "            predicted_labels = outputs.argmax(dim=2)\n",
    "\n",
    "            batch_size_seq = batch_sequences.shape[0]\n",
    "\n",
    "            for i in range(batch_size_seq):\n",
    "                seq = batch_sequences[i]\n",
    "                true_labels = batch_labels[i]\n",
    "                pred_labels = predicted_labels[i]\n",
    "\n",
    "                word = \"\"\n",
    "                last_char_true = None\n",
    "                last_char_pred = None\n",
    "\n",
    "                for idx, c in enumerate(seq):\n",
    "                    if c in [0, 2, 8, 15, 16, 26, 40, 43]:\n",
    "                        if word:\n",
    "                            last_char_true_val = (\n",
    "                                last_char_true if last_char_true is not None else 0\n",
    "                            )\n",
    "                            last_char_pred_val = (\n",
    "                                last_char_pred if last_char_pred is not None else 0\n",
    "                            )\n",
    "                            words_text.append(\n",
    "                                f\"{word}:{last_char_true_val}->{last_char_pred_val}\"\n",
    "                            )\n",
    "                            if last_char_true_val == last_char_pred_val:\n",
    "                                correct_last_char += 1\n",
    "                            total_last_char += 1\n",
    "\n",
    "                            word = \"\"\n",
    "                            last_char_true = None\n",
    "                            last_char_pred = None\n",
    "                        continue\n",
    "\n",
    "                    word += index_to_char[int(c)]\n",
    "                    last_char_true = index_to_label[int(true_labels[idx])]\n",
    "                    last_char_pred = index_to_label[int(pred_labels[idx])]\n",
    "\n",
    "                # catch last word\n",
    "                if word:\n",
    "                    last_char_true_val = (\n",
    "                        last_char_true if last_char_true is not None else 0\n",
    "                    )\n",
    "                    last_char_pred_val = (\n",
    "                        last_char_pred if last_char_pred is not None else 0\n",
    "                    )\n",
    "                    words_text.append(\n",
    "                        f\"{word}:{last_char_true_val}->{last_char_pred_val}\"\n",
    "                    )\n",
    "                    if last_char_true_val == last_char_pred_val:\n",
    "                        correct_last_char += 1\n",
    "                    total_last_char += 1\n",
    "\n",
    "    accuracy = correct_last_char / total_last_char if total_last_char > 0 else 0\n",
    "    print(f\"Last Character Accuracy: {accuracy*100:.3f}%\")\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize preprocessing classes\n",
    "    cleaner = TextCleaner()\n",
    "    preprocessor = TextPreprocessor(\n",
    "        cleaner, input_path=READ_PATH, output_path=WRITE_PATH\n",
    "    )\n",
    "    dataset_builder = DatasetBuilder(\n",
    "        preprocessor,\n",
    "        char_to_index=CHAR_TO_INDEX,\n",
    "        label_map=LABELS,\n",
    "        max_length=MAX_LENGTH,\n",
    "        device=DEVICE,\n",
    "    )\n",
    "\n",
    "    # Prepare dataloaders\n",
    "    # train_loader = dataset_builder.create_dataloader(\n",
    "    #     data_type=\"train\", batch_size=TRAIN_BATCH_SIZE\n",
    "    # )\n",
    "    # val_loader = dataset_builder.create_dataloader(\n",
    "    #     data_type=\"val\", batch_size=VAL_BATCH_SIZE\n",
    "    # )\n",
    "    # test_loader = dataset_builder.create_dataloader(\n",
    "    #     data_type=\"test\", batch_size=VAL_BATCH_SIZE, with_labels=False\n",
    "    # )\n",
    "\n",
    "    # Initialize model\n",
    "    vocab_size = len(CHAR_TO_INDEX) + 1\n",
    "    embedding_dim = 300\n",
    "    hidden_dim = 256\n",
    "    output_dim = len(LABELS)\n",
    "    dropout_rate = 0.2\n",
    "    num_layers = 5\n",
    "\n",
    "    model = CharBiLSTM(\n",
    "        vocab_size,\n",
    "        embedding_dim,\n",
    "        hidden_dim,\n",
    "        output_dim,\n",
    "        dropout_rate,\n",
    "        num_layers,\n",
    "        max_length=MAX_LENGTH,\n",
    "    ).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "    # Train the model\n",
    "    # criterion = torch.nn.CrossEntropyLoss()\n",
    "    # trainer = Trainer(\n",
    "    #     model=model,\n",
    "    #     optimizer=optimizer,\n",
    "    #     scheduler=scheduler,\n",
    "    #     criterion=criterion,\n",
    "    #     train_loader=train_loader,\n",
    "    #     val_loader=val_loader,\n",
    "    #     device=DEVICE,\n",
    "    #     checkpoint_file=\"checkpoint.pth\",\n",
    "    # )\n",
    "\n",
    "    # trainer.train(num_epochs=20)\n",
    "\n",
    "    # Load best model for prediction\n",
    "    model, meta = CharBiLSTM.load_model_pth()\n",
    "    predictor = Predictor(model, CHAR_TO_INDEX, INDEX_TO_LABEL, device=DEVICE)\n",
    "\n",
    "    def diacritize_text(text):\n",
    "        if not text or not text.strip():\n",
    "            return \"\"\n",
    "\n",
    "        try:\n",
    "            predicted_sentence = predictor.predict_sentence(text, max_length=MAX_LENGTH)\n",
    "            return predicted_sentence\n",
    "        except Exception as e:\n",
    "            return f\"Error during prediction: {str(e)}\"\n",
    "\n",
    "    iface = gr.Interface(\n",
    "        fn=diacritize_text,\n",
    "        inputs=gr.Textbox(\n",
    "            lines=2,\n",
    "            placeholder=\"Enter Arabic text here...\",\n",
    "            label=\"Input Sentence\",\n",
    "            rtl=True,\n",
    "        ),\n",
    "        outputs=gr.Textbox(label=\"Diacritized Sentence\", rtl=True),\n",
    "        title=\"Arabic Diacritization\",\n",
    "        description=\"Enter an Arabic sentence to predict its diacritics.\",\n",
    "    )\n",
    "    iface.launch()\n",
    "    # Predict on test dataset\n",
    "    # predictor.predict_dataset(test_loader)\n",
    "\n",
    "    # Predict a single sentence\n",
    "    # test_sentence = ''\n",
    "    # predicted_sentence = predictor.predict_sentence(test_sentence, max_length=MAX_LENGTH, batch_size=VAL_BATCH_SIZE)\n",
    "    # print(\"Original sentence:\", test_sentence)\n",
    "    # print(\"Predicted sentence:\", predicted_sentence)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    # predictor.evaluate(val_loader)\n"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T23:19:36.922016Z",
     "iopub.execute_input": "2025-12-09T23:19:36.922367Z",
     "iopub.status.idle": "2025-12-09T23:19:36.947366Z",
     "shell.execute_reply.started": "2025-12-09T23:19:36.922347Z",
     "shell.execute_reply": "2025-12-09T23:19:36.946597Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": "model, meta = CharBiLSTM.load_model()",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T23:21:33.825768Z",
     "iopub.execute_input": "2025-12-09T23:21:33.826288Z",
     "iopub.status.idle": "2025-12-09T23:21:35.012994Z",
     "shell.execute_reply.started": "2025-12-09T23:21:33.826266Z",
     "shell.execute_reply": "2025-12-09T23:21:35.012416Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": "meta",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T23:21:36.205089Z",
     "iopub.execute_input": "2025-12-09T23:21:36.205818Z",
     "iopub.status.idle": "2025-12-09T23:21:36.211331Z",
     "shell.execute_reply.started": "2025-12-09T23:21:36.205794Z",
     "shell.execute_reply": "2025-12-09T23:21:36.210480Z"
    }
   },
   "outputs": [
    {
     "execution_count": 13,
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'model_type': 'CharLSTM',\n 'best_f1': 0.934231058215857,\n 'embedding_size': 300,\n 'hidden_size': 256,\n 'num_layers': 5,\n 'dropout_rate': 0.2,\n 'learning_rate': 0.001,\n 'num_epochs': 19,\n 'max_sequence_length': 600,\n 'batch_size': 32,\n 'vocab_size': 44,\n 'output_classes': 16,\n 'model_file': 'best_model.pkl'}"
     },
     "metadata": {}
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": "predictor = Predictor(model, CHAR_TO_INDEX, INDEX_TO_LABEL, device=DEVICE)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T23:21:48.280996Z",
     "iopub.execute_input": "2025-12-09T23:21:48.281556Z",
     "iopub.status.idle": "2025-12-09T23:21:48.291375Z",
     "shell.execute_reply.started": "2025-12-09T23:21:48.281533Z",
     "shell.execute_reply": "2025-12-09T23:21:48.290845Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": "train_loader = dataset_builder.create_dataloader(data_type='train', batch_size=TRAIN_BATCH_SIZE)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T11:57:57.843220Z",
     "iopub.execute_input": "2025-12-09T11:57:57.843868Z",
     "iopub.status.idle": "2025-12-09T11:58:28.727564Z",
     "shell.execute_reply.started": "2025-12-09T11:57:57.843844Z",
     "shell.execute_reply": "2025-12-09T11:58:28.726906Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": "predictor.evaluate(train_loader)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T11:58:28.728781Z",
     "iopub.execute_input": "2025-12-09T11:58:28.729056Z",
     "iopub.status.idle": "2025-12-09T12:02:00.396263Z",
     "shell.execute_reply.started": "2025-12-09T11:58:28.729031Z",
     "shell.execute_reply": "2025-12-09T12:02:00.395427Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "Evaluating: 100%|██████████| 1678/1678 [03:31<00:00,  7.93it/s]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "8029990\nTest Accuracy: 96.151%\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    },
    {
     "execution_count": 14,
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9615052569138062"
     },
     "metadata": {}
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": "val_loader = dataset_builder.create_dataloader(data_type='val', batch_size=VAL_BATCH_SIZE)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T12:04:48.204287Z",
     "iopub.execute_input": "2025-12-09T12:04:48.204878Z",
     "iopub.status.idle": "2025-12-09T12:04:49.691161Z",
     "shell.execute_reply.started": "2025-12-09T12:04:48.204852Z",
     "shell.execute_reply": "2025-12-09T12:04:49.690538Z"
    }
   },
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": "predictor.evaluate(val_loader)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T12:04:51.999705Z",
     "iopub.execute_input": "2025-12-09T12:04:51.999977Z",
     "iopub.status.idle": "2025-12-09T12:05:00.110303Z",
     "shell.execute_reply.started": "2025-12-09T12:04:51.999958Z",
     "shell.execute_reply": "2025-12-09T12:05:00.109732Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": "Evaluating: 100%|██████████| 11/11 [00:08<00:00,  1.36it/s]\n",
     "output_type": "stream"
    },
    {
     "execution_count": 18,
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9691978862307833"
     },
     "metadata": {}
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": "test_loader = dataset_builder.create_dataloader(data_type='test', batch_size=VAL_BATCH_SIZE, with_labels=False)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T12:09:35.476918Z",
     "iopub.execute_input": "2025-12-09T12:09:35.477264Z",
     "iopub.status.idle": "2025-12-09T12:09:36.304155Z",
     "shell.execute_reply.started": "2025-12-09T12:09:35.477242Z",
     "shell.execute_reply": "2025-12-09T12:09:36.303550Z"
    }
   },
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "source": "predictor.predict_dataset(test_loader);",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T12:10:09.366057Z",
     "iopub.execute_input": "2025-12-09T12:10:09.366804Z",
     "iopub.status.idle": "2025-12-09T12:10:16.724801Z",
     "shell.execute_reply.started": "2025-12-09T12:10:09.366778Z",
     "shell.execute_reply": "2025-12-09T12:10:16.723790Z"
    }
   },
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "source": "import pandas as pd\ntest = pd.read_csv('/kaggle/working/submission.csv')\ntest",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T12:11:16.286684Z",
     "iopub.execute_input": "2025-12-09T12:11:16.287280Z",
     "iopub.status.idle": "2025-12-09T12:11:16.346998Z",
     "shell.execute_reply.started": "2025-12-09T12:11:16.287255Z",
     "shell.execute_reply": "2025-12-09T12:11:16.346296Z"
    }
   },
   "outputs": [
    {
     "execution_count": 33,
     "output_type": "execute_result",
     "data": {
      "text/plain": "            ID  label\n0            0      4\n1            1     14\n2            2     14\n3            3      6\n4            4      4\n...        ...    ...\n237235  237235      6\n237236  237236      4\n237237  237237      0\n237238  237238      6\n237239  237239      3\n\n[237240 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>237235</th>\n      <td>237235</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>237236</th>\n      <td>237236</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>237237</th>\n      <td>237237</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>237238</th>\n      <td>237238</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>237239</th>\n      <td>237239</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>237240 rows × 2 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "source": "import pandas as pd\ntest = pd.read_csv('/kaggle/input/contest-data/cufe-cmp-mainstream-nlp-fall-2025/test_no_diacritics.csv')\ntest",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T12:13:03.250955Z",
     "iopub.execute_input": "2025-12-09T12:13:03.251571Z",
     "iopub.status.idle": "2025-12-09T12:13:03.360836Z",
     "shell.execute_reply.started": "2025-12-09T12:13:03.251546Z",
     "shell.execute_reply": "2025-12-09T12:13:03.360170Z"
    }
   },
   "outputs": [
    {
     "execution_count": 35,
     "output_type": "execute_result",
     "data": {
      "text/plain": "            id  line_number letter  case_ending\n0            0            0      ف        False\n1            1            0      ي         True\n2            2            0      ا        False\n3            3            0      ل        False\n4            4            0      م        False\n...        ...          ...    ...          ...\n237235  237235         2468      ب        False\n237236  237236         2468      ن         True\n237237  237237         2468      ش        False\n237238  237238         2468      ي        False\n237239  237239         2468      ء         True\n\n[237240 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>line_number</th>\n      <th>letter</th>\n      <th>case_ending</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>ف</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0</td>\n      <td>ي</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0</td>\n      <td>ا</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0</td>\n      <td>ل</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0</td>\n      <td>م</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>237235</th>\n      <td>237235</td>\n      <td>2468</td>\n      <td>ب</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>237236</th>\n      <td>237236</td>\n      <td>2468</td>\n      <td>ن</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>237237</th>\n      <td>237237</td>\n      <td>2468</td>\n      <td>ش</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>237238</th>\n      <td>237238</td>\n      <td>2468</td>\n      <td>ي</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>237239</th>\n      <td>237239</td>\n      <td>2468</td>\n      <td>ء</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>237240 rows × 4 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "source": "gold = pd.read_csv('submission.csv')\ngold",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T12:13:18.454023Z",
     "iopub.execute_input": "2025-12-09T12:13:18.454631Z",
     "iopub.status.idle": "2025-12-09T12:13:18.491934Z",
     "shell.execute_reply.started": "2025-12-09T12:13:18.454607Z",
     "shell.execute_reply": "2025-12-09T12:13:18.491279Z"
    }
   },
   "outputs": [
    {
     "execution_count": 36,
     "output_type": "execute_result",
     "data": {
      "text/plain": "            ID  label\n0            0      4\n1            1     14\n2            2     14\n3            3      6\n4            4      4\n...        ...    ...\n237235  237235      6\n237236  237236      4\n237237  237237      0\n237238  237238      6\n237239  237239      3\n\n[237240 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>237235</th>\n      <td>237235</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>237236</th>\n      <td>237236</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>237237</th>\n      <td>237237</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>237238</th>\n      <td>237238</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>237239</th>\n      <td>237239</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>237240 rows × 2 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "source": "gold[test.case_ending]",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T12:13:24.770719Z",
     "iopub.execute_input": "2025-12-09T12:13:24.771514Z",
     "iopub.status.idle": "2025-12-09T12:13:24.781918Z",
     "shell.execute_reply.started": "2025-12-09T12:13:24.771489Z",
     "shell.execute_reply": "2025-12-09T12:13:24.781128Z"
    }
   },
   "outputs": [
    {
     "execution_count": 37,
     "output_type": "execute_result",
     "data": {
      "text/plain": "            ID  label\n1            1     14\n7            7      4\n12          12     12\n18          18      4\n20          20      6\n...        ...    ...\n237224  237224     14\n237228  237228      2\n237231  237231     14\n237236  237236      4\n237239  237239      3\n\n[56736 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>18</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>20</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>237224</th>\n      <td>237224</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>237228</th>\n      <td>237228</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>237231</th>\n      <td>237231</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>237236</th>\n      <td>237236</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>237239</th>\n      <td>237239</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n<p>56736 rows × 2 columns</p>\n</div>"
     },
     "metadata": {}
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "source": "gold[test.case_ending].to_csv(\"saved_data.csv\", index=False, encoding=\"utf-8\")",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T12:13:32.967645Z",
     "iopub.execute_input": "2025-12-09T12:13:32.968205Z",
     "iopub.status.idle": "2025-12-09T12:13:33.016662Z",
     "shell.execute_reply.started": "2025-12-09T12:13:32.968179Z",
     "shell.execute_reply": "2025-12-09T12:13:33.015880Z"
    }
   },
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "source": [
    "# from huggingface_hub import hf_hub_download\n",
    "# from huggingface_hub import login\n",
    "# repo_id = \"OmarHashem80/LSTM98\"\n",
    "# model_file = \"best_model.pkl\"\n",
    "# meta_file = \"best_model_meta.json\"\n",
    "\n",
    "# # download from HF Hub\n",
    "# local_model_path = hf_hub_download(repo_id=repo_id, filename=model_file)\n",
    "# local_meta_path = hf_hub_download(repo_id=repo_id, filename=meta_file)\n",
    "\n",
    "# print(\"Downloaded model:\", local_model_path)\n",
    "# import shutil\n",
    "\n",
    "# destination_path = '/kaggle/working/best_model.pkl'\n",
    "\n",
    "# shutil.copy(local_model_path, destination_path)\n",
    "# print(f'Model saved to {destination_path}')\n",
    "\n",
    "# destination_path = '/kaggle/working/best_model_meta.json'\n",
    "\n",
    "# shutil.copy(local_meta_path, destination_path)\n",
    "# print(f'Model saved to {destination_path}')"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T22:39:38.859971Z",
     "iopub.execute_input": "2025-12-09T22:39:38.860699Z",
     "iopub.status.idle": "2025-12-09T22:39:40.745664Z",
     "shell.execute_reply.started": "2025-12-09T22:39:38.860677Z",
     "shell.execute_reply": "2025-12-09T22:39:40.744058Z"
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "best_model_meta.json:   0%|          | 0.00/339 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9740aa39fa324a9a9cdac3af2f1b1b11"
      }
     },
     "metadata": {}
    },
    {
     "name": "stdout",
     "text": "Downloaded model: /root/.cache/huggingface/hub/models--OmarHashem80--LSTM98/snapshots/064a2a433e8f9d0d2a72b0f2185af280380d6fe8/best_model.pkl\nModel saved to /kaggle/working/best_model.pkl\nModel saved to /kaggle/working/best_model_meta.json\n",
     "output_type": "stream"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": "max_len = 600",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T22:44:39.199565Z",
     "iopub.execute_input": "2025-12-09T22:44:39.200180Z",
     "iopub.status.idle": "2025-12-09T22:44:39.203804Z",
     "shell.execute_reply.started": "2025-12-09T22:44:39.200156Z",
     "shell.execute_reply": "2025-12-09T22:44:39.202974Z"
    }
   },
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": "model_file = \"best_model.pkl\"\nmeta_file = \"best_model_meta.json\"\nmodel, _ = CharBiLSTM.load_model(model_file, meta_file)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T23:20:17.009951Z",
     "iopub.execute_input": "2025-12-09T23:20:17.010654Z",
     "iopub.status.idle": "2025-12-09T23:20:19.109084Z",
     "shell.execute_reply.started": "2025-12-09T23:20:17.010612Z",
     "shell.execute_reply": "2025-12-09T23:20:19.108496Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": "def test_last_char_text(model, data_loader, max_len=600, batch_size=256,\n                        char_to_index=CHAR_TO_INDEX, index_to_label=INDEX_TO_LABEL, labels=LABELS, index_to_char=INDEX_TO_CHAR):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(device)\n\n    model.eval()\n\n    total_last_char = 0\n    correct_last_char = 0\n    words_text = []\n\n    with torch.inference_mode():\n        for batch_sequences, batch_labels in tqdm(data_loader, desc=\"Last Char Test\"):\n            outputs = model(batch_sequences)  # batch_size * seq_length * output_size\n            predicted_labels = outputs.argmax(dim=2)\n\n            batch_size_seq = batch_sequences.shape[0]\n\n            for i in range(batch_size_seq):\n                seq = batch_sequences[i]\n                true_labels = batch_labels[i]\n                pred_labels = predicted_labels[i]\n\n                word = ''\n                last_char_true = None\n                last_char_pred = None\n\n                for idx, c in enumerate(seq):\n                    if c in [0, 2, 8, 15, 16, 26, 40, 43]:  # padding/unwanted chars\n                        if word:\n                            last_char_true_val = last_char_true if last_char_true is not None else 0\n                            last_char_pred_val = last_char_pred if last_char_pred is not None else 0\n                            words_text.append(f\"{word}:{last_char_true_val}->{last_char_pred_val}\")\n                            if last_char_true_val == last_char_pred_val:\n                                correct_last_char += 1\n                            total_last_char += 1\n\n                            word = ''\n                            last_char_true = None\n                            last_char_pred = None\n                        continue\n\n                    word += index_to_char[int(c)]\n                    last_char_true = index_to_label[int(true_labels[idx])]\n                    last_char_pred = index_to_label[int(pred_labels[idx])]\n\n                # catch last word in sequence\n                if word:\n                    last_char_true_val = last_char_true if last_char_true is not None else 0\n                    last_char_pred_val = last_char_pred if last_char_pred is not None else 0\n                    words_text.append(f\"{word}:{last_char_true_val}->{last_char_pred_val}\")\n                    if last_char_true_val == last_char_pred_val:\n                        correct_last_char += 1\n                    total_last_char += 1\n\n    accuracy = correct_last_char / total_last_char if total_last_char > 0 else 0\n    print(f\"Last Character Accuracy: {accuracy*100:.3f}%\")\n\n    return accuracy\n",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T23:29:48.284207Z",
     "iopub.execute_input": "2025-12-09T23:29:48.284497Z",
     "iopub.status.idle": "2025-12-09T23:29:48.293022Z",
     "shell.execute_reply.started": "2025-12-09T23:29:48.284477Z",
     "shell.execute_reply": "2025-12-09T23:29:48.292322Z"
    }
   },
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": "val_loader = dataset_builder.create_dataloader(data_type='val', batch_size=VAL_BATCH_SIZE)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T23:25:17.111791Z",
     "iopub.execute_input": "2025-12-09T23:25:17.112488Z",
     "iopub.status.idle": "2025-12-09T23:25:18.495282Z",
     "shell.execute_reply.started": "2025-12-09T23:25:17.112462Z",
     "shell.execute_reply": "2025-12-09T23:25:18.494687Z"
    }
   },
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": "test_last_char_text(model, val_loader)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T23:21:58.114250Z",
     "iopub.execute_input": "2025-12-09T23:21:58.114520Z",
     "iopub.status.idle": "2025-12-09T23:24:11.149458Z",
     "shell.execute_reply.started": "2025-12-09T23:21:58.114502Z",
     "shell.execute_reply": "2025-12-09T23:24:11.148835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "cuda\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Last Char Test: 100%|██████████| 11/11 [02:11<00:00, 11.96s/it]",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Last Character Accuracy: 96.553%\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "\n",
     "output_type": "stream"
    },
    {
     "execution_count": 16,
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9655344021702007"
     },
     "metadata": {}
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": "train_loader = dataset_builder.create_dataloader(data_type='train', batch_size=VAL_BATCH_SIZE)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T23:31:18.952371Z",
     "iopub.execute_input": "2025-12-09T23:31:18.953119Z",
     "iopub.status.idle": "2025-12-09T23:31:48.002336Z",
     "shell.execute_reply.started": "2025-12-09T23:31:18.953085Z",
     "shell.execute_reply": "2025-12-09T23:31:48.001680Z"
    }
   },
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "source": "test_last_char_text(model, data_loader=train_loader)",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-12-09T23:31:48.003462Z",
     "iopub.execute_input": "2025-12-09T23:31:48.003709Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": "cuda\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "Last Char Test:  10%|▉         | 20/210 [04:11<39:42, 12.54s/it]",
     "output_type": "stream"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
